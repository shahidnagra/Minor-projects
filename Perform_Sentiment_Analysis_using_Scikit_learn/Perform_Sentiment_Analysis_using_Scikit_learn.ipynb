{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Perform Sentiment Analysis using Scikit-learn.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahidnagra/Minor-projects/blob/main/Perform_Sentiment_Analysis_using_Scikit_learn/Perform_Sentiment_Analysis_using_Scikit_learn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "yRhZHmu3wn9o",
        "outputId": "d08bc878-f1c8-4a22-c6ab-8f787a698cc7"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('movie_data.csv')\n",
        "df.head(10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OK... so... I really like Kris Kristofferson a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>***SPOILER*** Do not read this, if you think a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hi for all the people who have seen this wonde...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I recently bought the DVD, forgetting just how...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Leave it to Braik to put on a good show. Final...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Nathan Detroit (Frank Sinatra) is the manager ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>To understand \"Crash Course\" in the right cont...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>I've been impressed with Chavez's stance again...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>This movie is directed by Renny Harlin the fin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  sentiment\n",
              "0  In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
              "1  OK... so... I really like Kris Kristofferson a...          0\n",
              "2  ***SPOILER*** Do not read this, if you think a...          0\n",
              "3  hi for all the people who have seen this wonde...          1\n",
              "4  I recently bought the DVD, forgetting just how...          0\n",
              "5  Leave it to Braik to put on a good show. Final...          1\n",
              "6  Nathan Detroit (Frank Sinatra) is the manager ...          1\n",
              "7  To understand \"Crash Course\" in the right cont...          1\n",
              "8  I've been impressed with Chavez's stance again...          1\n",
              "9  This movie is directed by Renny Harlin the fin...          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "5UXz9WQvwn9p",
        "outputId": "817a84ad-2e34-49cf-e90c-0882081c3e26"
      },
      "source": [
        "df['review'][0]\n",
        "#the last sentence says my vote is 7 which makes sense that classification above shows positive"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'In 1974, the teenager Martha Moxley (Maggie Grace) moves to the high-class area of Belle Haven, Greenwich, Connecticut. On the Mischief Night, eve of Halloween, she was murdered in the backyard of her house and her murder remained unsolved. Twenty-two years later, the writer Mark Fuhrman (Christopher Meloni), who is a former LA detective that has fallen in disgrace for perjury in O.J. Simpson trial and moved to Idaho, decides to investigate the case with his partner Stephen Weeks (Andrew Mitchell) with the purpose of writing a book. The locals squirm and do not welcome them, but with the support of the retired detective Steve Carroll (Robert Forster) that was in charge of the investigation in the 70\\'s, they discover the criminal and a net of power and money to cover the murder.<br /><br />\"Murder in Greenwich\" is a good TV movie, with the true story of a murder of a fifteen years old girl that was committed by a wealthy teenager whose mother was a Kennedy. The powerful and rich family used their influence to cover the murder for more than twenty years. However, a snoopy detective and convicted perjurer in disgrace was able to disclose how the hideous crime was committed. The screenplay shows the investigation of Mark and the last days of Martha in parallel, but there is a lack of the emotion in the dramatization. My vote is seven.<br /><br />Title (Brazil): Not Available'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-lxXALmwn9q"
      },
      "source": [
        "### Bag of words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVFh-WRVwn9r"
      },
      "source": [
        "Below, we will call the fit_transform method on CountVectorizer. This will construct the vocabulary of the bag-of-words model and transform the following three sentences into sparse feature vectors:\n",
        "1. The sun is shining\n",
        "2. The weather is sweet\n",
        "3. The sun is shining, the weather is sweet, and one and one is two\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7A1yw57uwn9s"
      },
      "source": [
        "#Lyrics of bob marley song\n",
        "#we want to change into sparse vector by using bag of words method\n",
        "#input this document, transform it into numerical values\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count = CountVectorizer()\n",
        "\n",
        "docs = np.array(['The sun is shining',\n",
        "                'The weather is sweet',\n",
        "                'The sun is shining, the weather is sweet, and one and one is two'])\n",
        "\n",
        "bag = count.fit_transform(docs)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p8z6uQjwn9t",
        "outputId": "700352ee-f955-489d-fd51-501539593a80"
      },
      "source": [
        "#vocabulary is saved in python dictionary\n",
        "#which maps the unique words in the docs to integer indeces\n",
        "\n",
        "print(count.vocabulary_)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'the': 6, 'sun': 4, 'is': 1, 'shining': 3, 'weather': 8, 'sweet': 5, 'and': 0, 'one': 2, 'two': 7}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdzM-tQDwn9t",
        "outputId": "0ade68be-0cf9-407d-89fb-0c86b51e86ed"
      },
      "source": [
        "print(bag.toarray())\n",
        "\n",
        "#N.B. Term frequency is number a word occurs in a document (count vector)\n",
        "# 'is' term frequency in 3rd sentence is 3\n",
        "#TFidf = Term Frequency Inverse Document Frequency\n",
        "# It is technique used to downweight those frequently occurring words in the feature vectors."
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 1 0 1 1 0 1 0 0]\n",
            " [0 1 0 0 0 1 1 0 1]\n",
            " [2 3 2 1 1 1 2 1 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-mTxh-Wwn9u"
      },
      "source": [
        "Raw term frequencies: *tf (t,d)*â€”the number of times a term t occurs in a document *d*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0LRSr6own95"
      },
      "source": [
        "###  Word relevancy using term frequency-inverse document frequency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8v0B7NHwn96"
      },
      "source": [
        "$$\\text{tf-idf}(t,d)=\\text{tf (t,d)}\\times \\text{idf}(t,d)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-zK40MGwn96"
      },
      "source": [
        "$$\\text{idf}(t,d) = \\text{log}\\frac{n_d}{1+\\text{df}(d, t)},$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ue5R-rx4wn96"
      },
      "source": [
        "where $n_d$ is the total number of documents, and df(d, t) is the number of documents d that contain the term t."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbWNc1KXwn96",
        "outputId": "b87965b3-578b-4992-92c2-96be0397c92a"
      },
      "source": [
        "# tf-idf is used to downweight the most frequent occuring words\n",
        "#nd is = 3 here\n",
        "# denominator is 1 to ensure non zeor\n",
        "#logarithm is used to ensure words are not given too much weights\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "np.set_printoptions(precision=2)   #so array looks non-messy\n",
        "\n",
        "tfidf = TfidfTransformer(use_idf = True, #enable reweighing\n",
        "                        norm = 'l2',   \n",
        "                         #each output will have a unit norm, here sum of squares of vector elements = 1\n",
        "                        smooth_idf = True   \n",
        "                         #weights by adding 1 to the document frequencies as if seen once more so avoid error of division by 0\n",
        "                        )\n",
        "\n",
        "print(tfidf.fit_transform(bag).toarray())\n",
        "\n",
        "# 'is' term frequency in 3rd sentence is deflated to 0.45 because repeated in sentence 1&2"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.   0.43 0.   0.56 0.56 0.   0.43 0.   0.  ]\n",
            " [0.   0.43 0.   0.   0.   0.56 0.43 0.   0.56]\n",
            " [0.5  0.45 0.5  0.19 0.19 0.19 0.3  0.25 0.19]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_OrSIMwwn97"
      },
      "source": [
        "The equations for the idf and tf-idf that are implemented in scikit-learn are:\n",
        "\n",
        "$$\\text{idf} (t,d) = log\\frac{1 + n_d}{1 + \\text{df}(d, t)}$$\n",
        "The tf-idf equation that is implemented in scikit-learn is as follows:\n",
        "\n",
        "$$\\text{tf-idf}(t,d) = \\text{tf}(t,d) \\times (\\text{idf}(t,d)+1)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MKijKGVwn97"
      },
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uFQUT3L2wn97",
        "outputId": "c3cfdb5d-b922-4228-fe16-dbf6d3ce7c05"
      },
      "source": [
        "df.loc[0, 'review'][-50:]\n",
        "#the last 50 characters\n",
        "#i have html, tags, commas and emojis might also be available"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'is seven.<br /><br />Title (Brazil): Not Available'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bl_FgtoWwn98"
      },
      "source": [
        "import re\n",
        "def preprocessor(text):\n",
        "    text = re.sub('<[^>]*>', '', text)\n",
        "    #replace html tags with a empty string\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
        "    #get text emojes like smiley face, disappointed, sad\n",
        "    text = re.sub('[\\W]+', ' ', text.lower()) +\\\n",
        "        ' '.join(emoticons).replace('-', '')\n",
        "    #we will move the emojis to end of text review\n",
        "    return text"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8jI-hexwwn98",
        "outputId": "b13fe4b7-64ab-44f5-ea45-2d03804f0c1f"
      },
      "source": [
        "preprocessor(df.loc[0, 'review'][-50:])\n",
        "#we will notice now panctuation like full stop, colon is not included\n",
        "#also html tags and whats in between them have also been removed"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'is seven title brazil not available'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iWQ7TuF2wn98",
        "outputId": "51a74cb3-a6f5-45c0-da28-4d3ac9ac638a"
      },
      "source": [
        "preprocessor(\"<,/a> this :) is a :( test :-) !\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' this is a test :) :( :)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJEy3rY-wn99"
      },
      "source": [
        "df['review'] = df['review'].apply(preprocessor)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTBMG8dYwn9-"
      },
      "source": [
        "###  Tokenization of documents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzqaOQ2kwn9-"
      },
      "source": [
        "#stemming to remove derivations of common words to a base word like organize, organized, organizer, organization\n",
        "# stemming chops words and remove derivations\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "porter = PorterStemmer()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1OUpjzzwn9_"
      },
      "source": [
        "#tokenize the text and split the sentence into words according to occurance\n",
        "#stemming technique\n",
        "\n",
        "def tokenizer(text):\n",
        "    return text.split()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgiZq8cLwn9_"
      },
      "source": [
        "def tokenizer_porter(text):\n",
        "    return[porter.stem(word) for word in text.split()]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeAZhIiLwn-A",
        "outputId": "34c202b9-f507-4079-e419-aad0a3a950e4"
      },
      "source": [
        "tokenizer('runners like running and thus they run')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['runners', 'like', 'running', 'and', 'thus', 'they', 'run']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytOoRexHwn-A",
        "outputId": "b6e26a38-9650-404c-bc7f-fedb14ed27ea"
      },
      "source": [
        "tokenizer_porter('runners like running and thus they run')\n",
        "\n",
        "#the ends of words have been stripped\n",
        "#idiosyncrncy like thus is changed to thu"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['runner', 'like', 'run', 'and', 'thu', 'they', 'run']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQKX7LvKwn-A",
        "outputId": "d5cfbab3-db20-431c-d81a-03679e414a09"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PM9L2YtCwn-B",
        "outputId": "537574ff-cbfe-43b3-ee73-444e7a6dfc4e"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop = stopwords.words('english')\n",
        "[w for w in tokenizer_porter('a runner likes running and thus she always runs a lot')[-10:] if w not in stop]\n",
        "\n",
        "#removed 'a', 'and'"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['runner', 'like', 'run', 'thu', 'alway', 'run', 'lot']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghN94m9Hwn-B"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RfZ64uMwn-B"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzZyCN_7wn-C"
      },
      "source": [
        "###  Transform Text Data into TF-IDF Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcLfvZPWwn-C"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(strip_accents = None,\n",
        "                        lowercase = False,\n",
        "                        preprocessor = None, #because we already did on our data\n",
        "                        tokenizer = tokenizer_porter, #stemming function\n",
        "                        use_idf = True,    #to downgrade according to frequency\n",
        "                        norm = 'l2',\n",
        "                        smooth_idf = True   #to avoid division by zero\n",
        "                       )\n",
        "\n",
        "#split to x, y components\n",
        "y = df.sentiment.values   #numpy array\n",
        "x = tfidf.fit_transform(df.review)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEi4pClYwn-C"
      },
      "source": [
        "###  Document Classification using Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOPBYwkXwn-D"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(x, y,\n",
        "                                                    random_state = 1, #to get same as instructor\n",
        "                                                    test_size = 0.5,\n",
        "                                                    shuffle = False\n",
        "                                                   )"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CR9DN7A-wn-D",
        "outputId": "5d2aa0af-802d-4f9d-84e0-aa4192b43f4d"
      },
      "source": [
        "import pickle\n",
        "#to dump our model on the disk\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "#Log Regression has hyperparemters and instead of manually trying to fine tune it\n",
        "#we can use estimator of sklearn CV\n",
        "#The output of a logistic model can be interpreted as a probability.\n",
        "\n",
        "#Cross validation can be used to:\n",
        "#1- Tune Model Hyperparamters\n",
        "#2- Assess model performance out of sample\n",
        "\n",
        "clf = LogisticRegressionCV(cv = 5, #cross validation fold\n",
        "                          scoring = 'accuracy',\n",
        "                          random_state = 0,\n",
        "                          n_jobs = -1, #to deticate all our CPU to solving this task\n",
        "                          verbose = 3, #to see output while doing computations\n",
        "                          max_iter = 300    #for safety of convergence\n",
        "                          ).fit(X_train, Y_train)\n",
        "\n",
        "saved_model = open('saved_model.sav', 'wb')  #write bytes to this file\n",
        "pickle.dump(clf, saved_model)\n",
        "saved_model.close()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.7min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDRwGXmpwn-E"
      },
      "source": [
        " ###  Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwlc4xkKwn-F"
      },
      "source": [
        "filename = 'saved_model.sav'\n",
        "saved_clf = pickle.load(open(filename, 'rb'))   #load from disk the saved model"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKSg2skqwn-F",
        "outputId": "33795628-af30-4ca1-fac1-d713dc766f20"
      },
      "source": [
        "saved_clf.score(X_test, Y_test)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.89608"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWGOiO2r01NB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}